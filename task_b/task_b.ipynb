{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task B - Caption Impact Analysis\n",
    "In this task , the impact of Captions on the object detection was studied.\n",
    "The analysis was done on output of same image with and without captions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative Analysis\n",
    "A visual comparison between the results of object detection of an image before and after object detection is shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "img_id=input()\n",
    "img_path = f\"../data/img/{img_id}.png\"\n",
    "# Check if the input image exists\n",
    "if not os.path.exists(img_path):\n",
    "    print(\"Input image not found.\")\n",
    "    raise(NameError)\n",
    "\n",
    "\n",
    "file_dir=\"curdir\"\n",
    "if os.path.exists(file_dir):\n",
    "    shutil.rmtree(file_dir)\n",
    "os.makedirs(file_dir)\n",
    "\n",
    "# Define the output image path\n",
    "output_image_path = os.path.join(file_dir, \"caption.jpg\")\n",
    "# Copy the input image to the output folder with the specified name\n",
    "shutil.copy(img_path, output_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here inpainting is done first to generate the image with no captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_ocr\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "# helper Function to calculate midpoint of a line\n",
    "def midpoint(x1, y1, x2, y2):\n",
    "    x_mid = int((x1 + x2) / 2)\n",
    "    y_mid = int((y1 + y2) / 2)\n",
    "    return (x_mid, y_mid)\n",
    "\n",
    "\n",
    "# Initialize keras-ocr pipeline\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "# Path to the image with text\n",
    "image_path = 'curdir/caption.jpg'\n",
    "\n",
    "# Read the image\n",
    "image = keras_ocr.tools.read(image_path) \n",
    "\n",
    "# Recognize text in the image\n",
    "predictions = pipeline.recognize([image])\n",
    "\n",
    "# Create a mask for inpainting\n",
    "mask = np.zeros(image.shape[:2], dtype=\"uint8\")\n",
    "\n",
    "# Iterate through predicted text regions and create mask\n",
    "for box in predictions[0]:\n",
    "    x0, y0 = box[1][0]\n",
    "    x1, y1 = box[1][1] \n",
    "    x2, y2 = box[1][2]\n",
    "    x3, y3 = box[1][3]\n",
    "    \n",
    "    # Calculate midpoints for line drawing\n",
    "    x_mid0, y_mid0 = midpoint(x1, y1, x2, y2)\n",
    "    x_mid1, y_mid1 = midpoint(x0, y0, x3, y3)\n",
    "    \n",
    "    # Calculate thickness based on line length\n",
    "    thickness = int(math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2))\n",
    "    \n",
    "    # Draw line on mask\n",
    "    cv2.line(mask, (x_mid0, y_mid0), (x_mid1, y_mid1), 255, thickness)\n",
    "\n",
    "# Inpaint the text regions\n",
    "inpainted_image = cv2.inpaint(image, mask, 7, cv2.INPAINT_NS)\n",
    "\n",
    "\n",
    "# Save the image without text\n",
    "cv2.imwrite('curdir/nocaption.jpg', cv2.cvtColor(inpainted_image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8m.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model(source=\"curdir/caption.jpg\", show=False, conf=0.5, save=True,project='curdir', name='captions')\n",
    "\n",
    "image = mpimg.imread(\"curdir/captions/caption.jpg\")\n",
    "\n",
    "    # Display the image\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Turn off axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_noc = model(source=\"curdir/nocaption.jpg\", show=False, conf=0.5, save=True,project='curdir', name='no_captions')\n",
    "\n",
    "image = mpimg.imread(\"curdir/no_captions/nocaption.jpg\")\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Turn off axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative Analysis of Captions\n",
    "The object detection was run on dev split and the number of instances where the there was a discrepancy between the two are counted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_lengths(file_path):\n",
    "    line_lengths = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # strip() removes leading and trailing whitespace including newlines\n",
    "            line_length = len(line.strip())\n",
    "            line_lengths.append(line_length)\n",
    "    return line_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "length_caption = get_line_lengths('objdetect_with_captions.txt')\n",
    "length_nocaption=get_line_lengths('objdetect_without_captions.txt')\n",
    "# print(length_caption)\n",
    "c=0\n",
    "for i in range(0,len(length_caption)):\n",
    "    if length_caption[i]!=length_nocaption[i]:\n",
    "        c+=1\n",
    "        \n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a more granular view of what objects are getting the more obstructed due to captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def process_file_lines(file_path):\n",
    "    # Open the file for reading\n",
    "    list=[]\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read lines from the file\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        # Process each line\n",
    "        for line in lines:\n",
    "            # You can add your processing logic here\n",
    "            # For example, print the line\n",
    "            list.append(line)\n",
    "    return list\n",
    "\n",
    "\n",
    "def count_dict(lines):\n",
    "    # A dictionary to store the count of each object\n",
    "    object_counts = defaultdict(int)\n",
    "\n",
    "    # Regular expression to find objects and their counts\n",
    "    pattern = re.compile(r'(\\d+) (\\w+(?: \\w+)*)')\n",
    "\n",
    "    # Process each line\n",
    "    for line in lines:\n",
    "        # Find all occurrences of the pattern\n",
    "        matches = pattern.findall(line)\n",
    "        for count, obj in matches:\n",
    "            # Convert plural objects to singular form for consistency\n",
    "            if obj.endswith('s'):\n",
    "                obj = obj[:-1]\n",
    "            # Update the count of the object\n",
    "            object_counts[obj] += int(count)\n",
    "\n",
    "    # Convert defaultdict to a regular dictionary for displat\n",
    "    object_counts = dict(object_counts)\n",
    "    return object_counts\n",
    "\n",
    "def display(dict):\n",
    "    words = list(dict.keys())\n",
    "    counts = list(dict.values())\n",
    "\n",
    "    # Creating the plot\n",
    "    plt.figure(figsize=(18, 6)) # Adjust the figure size as needed\n",
    "    plt.bar(words, counts, color='skyblue')\n",
    "\n",
    "    # Adding titles and labels\n",
    "    plt.title('Word Count Plot')\n",
    "    plt.xlabel('Words')\n",
    "    plt.ylabel('Counts')\n",
    "\n",
    "    # Rotating the x-axis labels\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example input lines\n",
    "lines_caption=process_file_lines('caption_obj.txt')\n",
    "lines_nocap=process_file_lines('no_caption_obj.txt')\n",
    "\n",
    "dict_with=count_dict(lines_caption)\n",
    "# print(dict_with)\n",
    "dict_without=count_dict(lines_nocap)\n",
    "# print(dict_without)\n",
    "\n",
    "nocap_person=dict_with['person']\n",
    "cap_person=dict_without['person']\n",
    "# print(nocap_person)\n",
    "# print(cap_person)\n",
    "del dict_with['person']\n",
    "del dict_without['person']\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18, 6)) \n",
    "words=[\"Persons With Caption\",\"Persons Without Caption\"]\n",
    "# counts.append(cap_person)\n",
    "# counts.append(nocap_person)\n",
    "counts=[cap_person,nocap_person]\n",
    "plt.bar(words, counts, color='skyblue')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Word Count Plot')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Counts')\n",
    "\n",
    "# Rotating the x-axis labels \n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "display(dict_with)\n",
    "display(dict_without)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
